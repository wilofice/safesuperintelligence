{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 0. Experimental ",
   "id": "1f9797059d05c1ec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T09:44:51.815467Z",
     "start_time": "2024-07-21T09:44:50.568881Z"
    }
   },
   "cell_type": "code",
   "source": "%pip install --upgrade langchain_experimental",
   "id": "e68b2dcc64ab9aa0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_experimental in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (0.0.62)\r\n",
      "Requirement already satisfied: langchain-community<0.3.0,>=0.2.6 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from langchain_experimental) (0.2.9)\r\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.10 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from langchain_experimental) (0.2.22)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from langchain-community<0.3.0,>=0.2.6->langchain_experimental) (6.0.1)\r\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from langchain-community<0.3.0,>=0.2.6->langchain_experimental) (2.0.30)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from langchain-community<0.3.0,>=0.2.6->langchain_experimental) (3.9.5)\r\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from langchain-community<0.3.0,>=0.2.6->langchain_experimental) (0.6.7)\r\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.9 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from langchain-community<0.3.0,>=0.2.6->langchain_experimental) (0.2.10)\r\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from langchain-community<0.3.0,>=0.2.6->langchain_experimental) (0.1.77)\r\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from langchain-community<0.3.0,>=0.2.6->langchain_experimental) (1.26.4)\r\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from langchain-community<0.3.0,>=0.2.6->langchain_experimental) (2.32.3)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from langchain-community<0.3.0,>=0.2.6->langchain_experimental) (8.3.0)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.10->langchain_experimental) (1.33)\r\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.10->langchain_experimental) (23.2)\r\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.10->langchain_experimental) (2.7.4)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.6->langchain_experimental) (1.3.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.6->langchain_experimental) (23.2.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.6->langchain_experimental) (1.4.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.6->langchain_experimental) (6.0.5)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3.0,>=0.2.6->langchain_experimental) (1.9.4)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.3.0,>=0.2.6->langchain_experimental) (3.21.3)\r\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.3.0,>=0.2.6->langchain_experimental) (0.9.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.10->langchain_experimental) (3.0.0)\r\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from langchain<0.3.0,>=0.2.9->langchain-community<0.3.0,>=0.2.6->langchain_experimental) (0.2.1)\r\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community<0.3.0,>=0.2.6->langchain_experimental) (3.10.4)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.10->langchain_experimental) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.10->langchain_experimental) (2.18.4)\r\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.10->langchain_experimental) (4.9.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from requests<3,>=2->langchain-community<0.3.0,>=0.2.6->langchain_experimental) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from requests<3,>=2->langchain-community<0.3.0,>=0.2.6->langchain_experimental) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from requests<3,>=2->langchain-community<0.3.0,>=0.2.6->langchain_experimental) (2.2.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from requests<3,>=2->langchain-community<0.3.0,>=0.2.6->langchain_experimental) (2024.6.2)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.3.0,>=0.2.6->langchain_experimental) (1.0.0)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T09:44:51.819335Z",
     "start_time": "2024-07-21T09:44:51.816680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = model.bind_tools(\n",
    "    tools=[\n",
    "        {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, \" \"e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"unit\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    "    function_call={\"name\": \"get_current_weather\"},\n",
    ")"
   ],
   "id": "6ebf97f61b46ef9f",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T09:44:52.313885Z",
     "start_time": "2024-07-21T09:44:51.819942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model.invoke(\"what is the weather in Boston?\")"
   ],
   "id": "241a36bba72c168c",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[39], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain_core\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmessages\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m HumanMessage\n\u001B[0;32m----> 3\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mwhat is the weather in Boston?\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/site-packages/langchain_core/runnables/base.py:5055\u001B[0m, in \u001B[0;36mRunnableBindingBase.invoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m   5049\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minvoke\u001B[39m(\n\u001B[1;32m   5050\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   5051\u001B[0m     \u001B[38;5;28minput\u001B[39m: Input,\n\u001B[1;32m   5052\u001B[0m     config: Optional[RunnableConfig] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   5053\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Optional[Any],\n\u001B[1;32m   5054\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Output:\n\u001B[0;32m-> 5055\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbound\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   5056\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5057\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_merge_configs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5058\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5059\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:265\u001B[0m, in \u001B[0;36mBaseChatModel.invoke\u001B[0;34m(self, input, config, stop, **kwargs)\u001B[0m\n\u001B[1;32m    254\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minvoke\u001B[39m(\n\u001B[1;32m    255\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    256\u001B[0m     \u001B[38;5;28minput\u001B[39m: LanguageModelInput,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    260\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m    261\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m BaseMessage:\n\u001B[1;32m    262\u001B[0m     config \u001B[38;5;241m=\u001B[39m ensure_config(config)\n\u001B[1;32m    263\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(\n\u001B[1;32m    264\u001B[0m         ChatGeneration,\n\u001B[0;32m--> 265\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate_prompt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    266\u001B[0m \u001B[43m            \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_convert_input\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    267\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    268\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcallbacks\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    269\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtags\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtags\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    270\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmetadata\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    271\u001B[0m \u001B[43m            \u001B[49m\u001B[43mrun_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrun_name\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    272\u001B[0m \u001B[43m            \u001B[49m\u001B[43mrun_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpop\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrun_id\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    273\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    274\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mgenerations[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m],\n\u001B[1;32m    275\u001B[0m     )\u001B[38;5;241m.\u001B[39mmessage\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:698\u001B[0m, in \u001B[0;36mBaseChatModel.generate_prompt\u001B[0;34m(self, prompts, stop, callbacks, **kwargs)\u001B[0m\n\u001B[1;32m    690\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgenerate_prompt\u001B[39m(\n\u001B[1;32m    691\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    692\u001B[0m     prompts: List[PromptValue],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    695\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m    696\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m LLMResult:\n\u001B[1;32m    697\u001B[0m     prompt_messages \u001B[38;5;241m=\u001B[39m [p\u001B[38;5;241m.\u001B[39mto_messages() \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m prompts]\n\u001B[0;32m--> 698\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt_messages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:555\u001B[0m, in \u001B[0;36mBaseChatModel.generate\u001B[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001B[0m\n\u001B[1;32m    553\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m run_managers:\n\u001B[1;32m    554\u001B[0m             run_managers[i]\u001B[38;5;241m.\u001B[39mon_llm_error(e, response\u001B[38;5;241m=\u001B[39mLLMResult(generations\u001B[38;5;241m=\u001B[39m[]))\n\u001B[0;32m--> 555\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m    556\u001B[0m flattened_outputs \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    557\u001B[0m     LLMResult(generations\u001B[38;5;241m=\u001B[39m[res\u001B[38;5;241m.\u001B[39mgenerations], llm_output\u001B[38;5;241m=\u001B[39mres\u001B[38;5;241m.\u001B[39mllm_output)  \u001B[38;5;66;03m# type: ignore[list-item]\u001B[39;00m\n\u001B[1;32m    558\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m results\n\u001B[1;32m    559\u001B[0m ]\n\u001B[1;32m    560\u001B[0m llm_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_combine_llm_outputs([res\u001B[38;5;241m.\u001B[39mllm_output \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m results])\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:545\u001B[0m, in \u001B[0;36mBaseChatModel.generate\u001B[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001B[0m\n\u001B[1;32m    542\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(messages):\n\u001B[1;32m    543\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    544\u001B[0m         results\u001B[38;5;241m.\u001B[39mappend(\n\u001B[0;32m--> 545\u001B[0m             \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_generate_with_cache\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    546\u001B[0m \u001B[43m                \u001B[49m\u001B[43mm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    547\u001B[0m \u001B[43m                \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    548\u001B[0m \u001B[43m                \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_managers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    549\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    550\u001B[0m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    551\u001B[0m         )\n\u001B[1;32m    552\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    553\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m run_managers:\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:770\u001B[0m, in \u001B[0;36mBaseChatModel._generate_with_cache\u001B[0;34m(self, messages, stop, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m    768\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    769\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m inspect\u001B[38;5;241m.\u001B[39msignature(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate)\u001B[38;5;241m.\u001B[39mparameters\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_manager\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 770\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_generate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    771\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    772\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    773\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    774\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate(messages, stop\u001B[38;5;241m=\u001B[39mstop, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/site-packages/langchain_experimental/llms/ollama_functions.py:363\u001B[0m, in \u001B[0;36mOllamaFunctions._generate\u001B[0;34m(self, messages, stop, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m    357\u001B[0m system_message_prompt_template \u001B[38;5;241m=\u001B[39m SystemMessagePromptTemplate\u001B[38;5;241m.\u001B[39mfrom_template(\n\u001B[1;32m    358\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtool_system_prompt_template\n\u001B[1;32m    359\u001B[0m )\n\u001B[1;32m    360\u001B[0m system_message \u001B[38;5;241m=\u001B[39m system_message_prompt_template\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    361\u001B[0m     tools\u001B[38;5;241m=\u001B[39mjson\u001B[38;5;241m.\u001B[39mdumps(functions, indent\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m    362\u001B[0m )\n\u001B[0;32m--> 363\u001B[0m response_message \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_generate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    364\u001B[0m \u001B[43m    \u001B[49m\u001B[43m[\u001B[49m\u001B[43msystem_message\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    365\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    366\u001B[0m chat_generation_content \u001B[38;5;241m=\u001B[39m response_message\u001B[38;5;241m.\u001B[39mgenerations[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mtext\n\u001B[1;32m    367\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(chat_generation_content, \u001B[38;5;28mstr\u001B[39m):\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/site-packages/langchain_community/chat_models/ollama.py:286\u001B[0m, in \u001B[0;36mChatOllama._generate\u001B[0;34m(self, messages, stop, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m    262\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_generate\u001B[39m(\n\u001B[1;32m    263\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    264\u001B[0m     messages: List[BaseMessage],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    267\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m    268\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ChatResult:\n\u001B[1;32m    269\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Call out to Ollama's generate endpoint.\u001B[39;00m\n\u001B[1;32m    270\u001B[0m \n\u001B[1;32m    271\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    283\u001B[0m \u001B[38;5;124;03m            ])\u001B[39;00m\n\u001B[1;32m    284\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 286\u001B[0m     final_chunk \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_chat_stream_with_aggregation\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    287\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    288\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    289\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    290\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    291\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    292\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    293\u001B[0m     chat_generation \u001B[38;5;241m=\u001B[39m ChatGeneration(\n\u001B[1;32m    294\u001B[0m         message\u001B[38;5;241m=\u001B[39mAIMessage(content\u001B[38;5;241m=\u001B[39mfinal_chunk\u001B[38;5;241m.\u001B[39mtext),\n\u001B[1;32m    295\u001B[0m         generation_info\u001B[38;5;241m=\u001B[39mfinal_chunk\u001B[38;5;241m.\u001B[39mgeneration_info,\n\u001B[1;32m    296\u001B[0m     )\n\u001B[1;32m    297\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ChatResult(generations\u001B[38;5;241m=\u001B[39m[chat_generation])\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/site-packages/langchain_community/chat_models/ollama.py:217\u001B[0m, in \u001B[0;36mChatOllama._chat_stream_with_aggregation\u001B[0;34m(self, messages, stop, run_manager, verbose, **kwargs)\u001B[0m\n\u001B[1;32m    208\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_chat_stream_with_aggregation\u001B[39m(\n\u001B[1;32m    209\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    210\u001B[0m     messages: List[BaseMessage],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    214\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m    215\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ChatGenerationChunk:\n\u001B[1;32m    216\u001B[0m     final_chunk: Optional[ChatGenerationChunk] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 217\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstream_resp\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_chat_stream\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m    218\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstream_resp\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m    219\u001B[0m \u001B[43m            \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m_chat_stream_response_to_chat_generation_chunk\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstream_resp\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/site-packages/langchain_community/chat_models/ollama.py:189\u001B[0m, in \u001B[0;36mChatOllama._create_chat_stream\u001B[0;34m(self, messages, stop, **kwargs)\u001B[0m\n\u001B[1;32m    179\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_create_chat_stream\u001B[39m(\n\u001B[1;32m    180\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    181\u001B[0m     messages: List[BaseMessage],\n\u001B[1;32m    182\u001B[0m     stop: Optional[List[\u001B[38;5;28mstr\u001B[39m]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    183\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m    184\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[\u001B[38;5;28mstr\u001B[39m]:\n\u001B[1;32m    185\u001B[0m     payload \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    186\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel,\n\u001B[1;32m    187\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_convert_messages_to_ollama_messages(messages),\n\u001B[1;32m    188\u001B[0m     }\n\u001B[0;32m--> 189\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_stream\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    190\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpayload\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpayload\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mapi_url\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbase_url\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m/api/chat\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    191\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/site-packages/langchain_community/llms/ollama.py:234\u001B[0m, in \u001B[0;36m_OllamaCommon._create_stream\u001B[0;34m(self, api_url, payload, stop, **kwargs)\u001B[0m\n\u001B[1;32m    228\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    229\u001B[0m     request_payload \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    230\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprompt\u001B[39m\u001B[38;5;124m\"\u001B[39m: payload\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprompt\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m    231\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimages\u001B[39m\u001B[38;5;124m\"\u001B[39m: payload\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimages\u001B[39m\u001B[38;5;124m\"\u001B[39m, []),\n\u001B[1;32m    232\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams,\n\u001B[1;32m    233\u001B[0m     }\n\u001B[0;32m--> 234\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43mrequests\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpost\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    235\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mapi_url\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    236\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\n\u001B[1;32m    237\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mContent-Type\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mapplication/json\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    238\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mdict\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    239\u001B[0m \u001B[43m    \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    240\u001B[0m \u001B[43m    \u001B[49m\u001B[43mjson\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_payload\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    241\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    242\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    243\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    244\u001B[0m response\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    245\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m response\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m200\u001B[39m:\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/site-packages/requests/api.py:115\u001B[0m, in \u001B[0;36mpost\u001B[0;34m(url, data, json, **kwargs)\u001B[0m\n\u001B[1;32m    103\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpost\u001B[39m(url, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, json\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    104\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Sends a POST request.\u001B[39;00m\n\u001B[1;32m    105\u001B[0m \n\u001B[1;32m    106\u001B[0m \u001B[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;124;03m    :rtype: requests.Response\u001B[39;00m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 115\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpost\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjson\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mjson\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/site-packages/requests/api.py:59\u001B[0m, in \u001B[0;36mrequest\u001B[0;34m(method, url, **kwargs)\u001B[0m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001B[39;00m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001B[39;00m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;66;03m# cases, and look like a memory leak in others.\u001B[39;00m\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m sessions\u001B[38;5;241m.\u001B[39mSession() \u001B[38;5;28;01mas\u001B[39;00m session:\n\u001B[0;32m---> 59\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/site-packages/requests/sessions.py:589\u001B[0m, in \u001B[0;36mSession.request\u001B[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[1;32m    584\u001B[0m send_kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    585\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m: timeout,\n\u001B[1;32m    586\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m: allow_redirects,\n\u001B[1;32m    587\u001B[0m }\n\u001B[1;32m    588\u001B[0m send_kwargs\u001B[38;5;241m.\u001B[39mupdate(settings)\n\u001B[0;32m--> 589\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msend_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    591\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/site-packages/requests/sessions.py:703\u001B[0m, in \u001B[0;36mSession.send\u001B[0;34m(self, request, **kwargs)\u001B[0m\n\u001B[1;32m    700\u001B[0m start \u001B[38;5;241m=\u001B[39m preferred_clock()\n\u001B[1;32m    702\u001B[0m \u001B[38;5;66;03m# Send the request\u001B[39;00m\n\u001B[0;32m--> 703\u001B[0m r \u001B[38;5;241m=\u001B[39m \u001B[43madapter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    705\u001B[0m \u001B[38;5;66;03m# Total elapsed time of the request (approximately)\u001B[39;00m\n\u001B[1;32m    706\u001B[0m elapsed \u001B[38;5;241m=\u001B[39m preferred_clock() \u001B[38;5;241m-\u001B[39m start\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/site-packages/requests/adapters.py:667\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[1;32m    664\u001B[0m     timeout \u001B[38;5;241m=\u001B[39m TimeoutSauce(connect\u001B[38;5;241m=\u001B[39mtimeout, read\u001B[38;5;241m=\u001B[39mtimeout)\n\u001B[1;32m    666\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 667\u001B[0m     resp \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    668\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    669\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    670\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    671\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    672\u001B[0m \u001B[43m        \u001B[49m\u001B[43mredirect\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    673\u001B[0m \u001B[43m        \u001B[49m\u001B[43massert_same_host\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    674\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    675\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    676\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    677\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    678\u001B[0m \u001B[43m        \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    679\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    681\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (ProtocolError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m    682\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m(err, request\u001B[38;5;241m=\u001B[39mrequest)\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/site-packages/urllib3/connectionpool.py:793\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001B[0m\n\u001B[1;32m    790\u001B[0m response_conn \u001B[38;5;241m=\u001B[39m conn \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m release_conn \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    792\u001B[0m \u001B[38;5;66;03m# Make the request on the HTTPConnection object\u001B[39;00m\n\u001B[0;32m--> 793\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    794\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    795\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    796\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    797\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_obj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    798\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    799\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    800\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    801\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    802\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresponse_conn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresponse_conn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    803\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpreload_content\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    804\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecode_content\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    805\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mresponse_kw\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    806\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    808\u001B[0m \u001B[38;5;66;03m# Everything went great!\u001B[39;00m\n\u001B[1;32m    809\u001B[0m clean_exit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/site-packages/urllib3/connectionpool.py:537\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001B[0m\n\u001B[1;32m    535\u001B[0m \u001B[38;5;66;03m# Receive the response from the server\u001B[39;00m\n\u001B[1;32m    536\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 537\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetresponse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    538\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (BaseSSLError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    539\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_raise_timeout(err\u001B[38;5;241m=\u001B[39me, url\u001B[38;5;241m=\u001B[39murl, timeout_value\u001B[38;5;241m=\u001B[39mread_timeout)\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/site-packages/urllib3/connection.py:466\u001B[0m, in \u001B[0;36mHTTPConnection.getresponse\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    463\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mresponse\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m HTTPResponse\n\u001B[1;32m    465\u001B[0m \u001B[38;5;66;03m# Get the response from http.client.HTTPConnection\u001B[39;00m\n\u001B[0;32m--> 466\u001B[0m httplib_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetresponse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    468\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    469\u001B[0m     assert_header_parsing(httplib_response\u001B[38;5;241m.\u001B[39mmsg)\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/http/client.py:1428\u001B[0m, in \u001B[0;36mHTTPConnection.getresponse\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1426\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1427\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1428\u001B[0m         \u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbegin\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1429\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m:\n\u001B[1;32m   1430\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/http/client.py:331\u001B[0m, in \u001B[0;36mHTTPResponse.begin\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    329\u001B[0m \u001B[38;5;66;03m# read until we get a non-100 response\u001B[39;00m\n\u001B[1;32m    330\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 331\u001B[0m     version, status, reason \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_read_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    332\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m status \u001B[38;5;241m!=\u001B[39m CONTINUE:\n\u001B[1;32m    333\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/http/client.py:292\u001B[0m, in \u001B[0;36mHTTPResponse._read_status\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    291\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_read_status\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 292\u001B[0m     line \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadline\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_MAXLINE\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miso-8859-1\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    293\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(line) \u001B[38;5;241m>\u001B[39m _MAXLINE:\n\u001B[1;32m    294\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m LineTooLong(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstatus line\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/socket.py:707\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    705\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    706\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 707\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    708\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[1;32m    709\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T09:44:52.315386Z",
     "start_time": "2024-07-21T09:44:52.315344Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.tools import tool\n",
    "from typing import Annotated"
   ],
   "id": "b84e5972a0d7da1c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from scraping.db.documents import ArticleDocument",
   "id": "3aadf010de15697a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "@tool\n",
    "def get_medium_article(link: Annotated[str, \"The link of the Medium article\"],) -> str:\n",
    "    \"\"\"Get a medium article from the given link\"\"\"\n",
    "    filter_options = {\"link\": link}\n",
    "    article = ArticleDocument.get(**filter_options)\n",
    "    return article.content['Content']"
   ],
   "id": "19c38f3664409351",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "link = \"https://medium.com/ai-in-plain-english/claude-3-5-sonnet-why-it-is-better-than-chatgpt-7709d7cbc237\"",
   "id": "618c8cbdc9ff09b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "r = get_medium_article(link)"
   ],
   "id": "5bebaf802506849b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(r)",
   "id": "9198f7f25f825dcb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "get_medium_article.args_schema.schema()\n",
   "id": "50539742f09c9f9b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T10:07:25.614491Z",
     "start_time": "2024-07-21T10:07:25.611422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "\n",
    "class AnswerWithJustification(BaseModel):\n",
    "    \"\"\"An answer to the user question along with justification for the answer.\"\"\"\n",
    "    answer: str\n",
    "    justification: str\n",
    "    \n",
    "model = OllamaFunctions(model=\"llama3-groq-tool-use\")\n",
    "structured_llm = model.with_structured_output(AnswerWithJustification, include_raw=True)\n",
    "#model = OllamaFunctions(model=\"llama3-groq-tool-use\", format=\"json\")"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Use the tools at your disposal at the best of your ability.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ],
   "id": "f2b317943f6c0c8c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T09:44:54.797220Z",
     "start_time": "2024-07-21T09:44:54.794464Z"
    }
   },
   "cell_type": "code",
   "source": "tools = [get_medium_article]",
   "id": "b088d08b54d9195d",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "llm = model.bind_tools(tools)",
   "id": "fab977ace2734939",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "chain = prompt | llm",
   "id": "9123abb197e53763",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T09:46:19.294179Z",
     "start_time": "2024-07-21T09:46:19.291791Z"
    }
   },
   "cell_type": "code",
   "source": "input = \"Can you tell me what this Medium article is about ? Here is the link to the article: https://medium.com/ai-in-plain-english/claude-3-5-sonnet-why-it-is-better-than-chatgpt-7709d7cbc237\"",
   "id": "775ba6c956606299",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ai_msg = chain.invoke(\n",
    "    {\n",
    "        \"input\": input,\n",
    "    }\n",
    ")"
   ],
   "id": "5ea4107139a6a462",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "available_tools = {\"get_medium_article\" : get_medium_article}",
   "id": "d439cfe782a8118c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "messages = [ai_msg]",
   "id": "ebc5b569a8b82e10",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = available_tools[tool_call[\"name\"].lower()]\n",
    "    if selected_tool:\n",
    "        tool_msg = selected_tool.invoke(tool_call)\n",
    "        messages.append(tool_msg)\n",
    "    else:\n",
    "        raise ValueError(f\"No tool called {tool_call['name'].lower()} was found\")"
   ],
   "id": "aee7e948b6b0fa6f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "messages",
   "id": "32890d5b719cc5bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from langchain.agents import AgentExecutor, create_tool_calling_agent",
   "id": "f68542a7df1d402",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T09:47:59.568444Z",
     "start_time": "2024-07-21T09:47:59.564989Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Make sure to use the get_medium_article tool to retrieve the content of the Medium article provided to you.\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n"
   ],
   "id": "a14596746a959505",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T10:10:44.564972Z",
     "start_time": "2024-07-21T10:10:44.563136Z"
    }
   },
   "cell_type": "code",
   "source": "agent = create_tool_calling_agent(model, tools, prompt)",
   "id": "e3794715e3bf2705",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T10:10:51.612918Z",
     "start_time": "2024-07-21T10:10:51.610474Z"
    }
   },
   "cell_type": "code",
   "source": "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
   "id": "a23b527f2e28be01",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T10:10:55.471904Z",
     "start_time": "2024-07-21T10:10:55.373262Z"
    }
   },
   "cell_type": "code",
   "source": "result = agent_executor.invoke({\"input\": input})",
   "id": "92c9fbfa3966379d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type StructuredTool is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[58], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43magent_executor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43minput\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/site-packages/langchain/chains/base.py:166\u001B[0m, in \u001B[0;36mChain.invoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m    164\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    165\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e)\n\u001B[0;32m--> 166\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m    167\u001B[0m run_manager\u001B[38;5;241m.\u001B[39mon_chain_end(outputs)\n\u001B[1;32m    169\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m include_run_info:\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/site-packages/langchain/chains/base.py:156\u001B[0m, in \u001B[0;36mChain.invoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m    153\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    154\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_inputs(inputs)\n\u001B[1;32m    155\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m--> 156\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    157\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m new_arg_supported\n\u001B[1;32m    158\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(inputs)\n\u001B[1;32m    159\u001B[0m     )\n\u001B[1;32m    161\u001B[0m     final_outputs: Dict[\u001B[38;5;28mstr\u001B[39m, Any] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprep_outputs(\n\u001B[1;32m    162\u001B[0m         inputs, outputs, return_only_outputs\n\u001B[1;32m    163\u001B[0m     )\n\u001B[1;32m    164\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/site-packages/langchain/agents/agent.py:1636\u001B[0m, in \u001B[0;36mAgentExecutor._call\u001B[0;34m(self, inputs, run_manager)\u001B[0m\n\u001B[1;32m   1634\u001B[0m \u001B[38;5;66;03m# We now enter the agent loop (until it returns something).\u001B[39;00m\n\u001B[1;32m   1635\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_continue(iterations, time_elapsed):\n\u001B[0;32m-> 1636\u001B[0m     next_step_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_take_next_step\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1637\u001B[0m \u001B[43m        \u001B[49m\u001B[43mname_to_tool_map\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1638\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcolor_mapping\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1639\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1640\u001B[0m \u001B[43m        \u001B[49m\u001B[43mintermediate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1641\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1642\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1643\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(next_step_output, AgentFinish):\n\u001B[1;32m   1644\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_return(\n\u001B[1;32m   1645\u001B[0m             next_step_output, intermediate_steps, run_manager\u001B[38;5;241m=\u001B[39mrun_manager\n\u001B[1;32m   1646\u001B[0m         )\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/site-packages/langchain/agents/agent.py:1342\u001B[0m, in \u001B[0;36mAgentExecutor._take_next_step\u001B[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001B[0m\n\u001B[1;32m   1333\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_take_next_step\u001B[39m(\n\u001B[1;32m   1334\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1335\u001B[0m     name_to_tool_map: Dict[\u001B[38;5;28mstr\u001B[39m, BaseTool],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1339\u001B[0m     run_manager: Optional[CallbackManagerForChainRun] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1340\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Union[AgentFinish, List[Tuple[AgentAction, \u001B[38;5;28mstr\u001B[39m]]]:\n\u001B[1;32m   1341\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_consume_next_step(\n\u001B[0;32m-> 1342\u001B[0m         \u001B[43m[\u001B[49m\n\u001B[1;32m   1343\u001B[0m \u001B[43m            \u001B[49m\u001B[43ma\u001B[49m\n\u001B[1;32m   1344\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43ma\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_iter_next_step\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1345\u001B[0m \u001B[43m                \u001B[49m\u001B[43mname_to_tool_map\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1346\u001B[0m \u001B[43m                \u001B[49m\u001B[43mcolor_mapping\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1347\u001B[0m \u001B[43m                \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1348\u001B[0m \u001B[43m                \u001B[49m\u001B[43mintermediate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1349\u001B[0m \u001B[43m                \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1350\u001B[0m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1351\u001B[0m \u001B[43m        \u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m   1352\u001B[0m     )\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/site-packages/langchain/agents/agent.py:1370\u001B[0m, in \u001B[0;36mAgentExecutor._iter_next_step\u001B[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001B[0m\n\u001B[1;32m   1367\u001B[0m     intermediate_steps \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_prepare_intermediate_steps(intermediate_steps)\n\u001B[1;32m   1369\u001B[0m     \u001B[38;5;66;03m# Call the LLM to see what to do.\u001B[39;00m\n\u001B[0;32m-> 1370\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43magent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mplan\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1371\u001B[0m \u001B[43m        \u001B[49m\u001B[43mintermediate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1372\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_child\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1373\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1374\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1375\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m OutputParserException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m   1376\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle_parsing_errors, \u001B[38;5;28mbool\u001B[39m):\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/site-packages/langchain/agents/agent.py:580\u001B[0m, in \u001B[0;36mRunnableMultiActionAgent.plan\u001B[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001B[0m\n\u001B[1;32m    572\u001B[0m final_output: Any \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    573\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstream_runnable:\n\u001B[1;32m    574\u001B[0m     \u001B[38;5;66;03m# Use streaming to make sure that the underlying LLM is invoked in a\u001B[39;00m\n\u001B[1;32m    575\u001B[0m     \u001B[38;5;66;03m# streaming\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    578\u001B[0m     \u001B[38;5;66;03m# Because the response from the plan is not a generator, we need to\u001B[39;00m\n\u001B[1;32m    579\u001B[0m     \u001B[38;5;66;03m# accumulate the output into final output and return that.\u001B[39;00m\n\u001B[0;32m--> 580\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrunnable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcallbacks\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m    581\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mfinal_output\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m:\u001B[49m\n\u001B[1;32m    582\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfinal_output\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/site-packages/langchain_core/runnables/base.py:3251\u001B[0m, in \u001B[0;36mRunnableSequence.stream\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m   3245\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstream\u001B[39m(\n\u001B[1;32m   3246\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   3247\u001B[0m     \u001B[38;5;28minput\u001B[39m: Input,\n\u001B[1;32m   3248\u001B[0m     config: Optional[RunnableConfig] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   3249\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Optional[Any],\n\u001B[1;32m   3250\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[Output]:\n\u001B[0;32m-> 3251\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform(\u001B[38;5;28miter\u001B[39m([\u001B[38;5;28minput\u001B[39m]), config, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/site-packages/langchain_core/runnables/base.py:3238\u001B[0m, in \u001B[0;36mRunnableSequence.transform\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m   3232\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtransform\u001B[39m(\n\u001B[1;32m   3233\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   3234\u001B[0m     \u001B[38;5;28minput\u001B[39m: Iterator[Input],\n\u001B[1;32m   3235\u001B[0m     config: Optional[RunnableConfig] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   3236\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Optional[Any],\n\u001B[1;32m   3237\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[Output]:\n\u001B[0;32m-> 3238\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_transform_stream_with_config(\n\u001B[1;32m   3239\u001B[0m         \u001B[38;5;28minput\u001B[39m,\n\u001B[1;32m   3240\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_transform,\n\u001B[1;32m   3241\u001B[0m         patch_config(config, run_name\u001B[38;5;241m=\u001B[39m(config \u001B[38;5;129;01mor\u001B[39;00m {})\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_name\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname),\n\u001B[1;32m   3242\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   3243\u001B[0m     )\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/site-packages/langchain_core/runnables/base.py:2052\u001B[0m, in \u001B[0;36mRunnable._transform_stream_with_config\u001B[0;34m(self, input, transformer, config, run_type, **kwargs)\u001B[0m\n\u001B[1;32m   2050\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   2051\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m-> 2052\u001B[0m         chunk: Output \u001B[38;5;241m=\u001B[39m \u001B[43mcontext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m   2053\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m chunk\n\u001B[1;32m   2054\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m final_output_supported:\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/site-packages/langchain_core/runnables/base.py:3200\u001B[0m, in \u001B[0;36mRunnableSequence._transform\u001B[0;34m(self, input, run_manager, config, **kwargs)\u001B[0m\n\u001B[1;32m   3197\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   3198\u001B[0m         final_pipeline \u001B[38;5;241m=\u001B[39m step\u001B[38;5;241m.\u001B[39mtransform(final_pipeline, config)\n\u001B[0;32m-> 3200\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43moutput\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mfinal_pipeline\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m   3201\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43moutput\u001B[49m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/site-packages/langchain_core/runnables/base.py:1270\u001B[0m, in \u001B[0;36mRunnable.transform\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m   1267\u001B[0m final: Input\n\u001B[1;32m   1268\u001B[0m got_first_val \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m-> 1270\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43michunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m:\u001B[49m\n\u001B[1;32m   1271\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# The default implementation of transform is to buffer input and\u001B[39;49;00m\n\u001B[1;32m   1272\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# then call stream.\u001B[39;49;00m\n\u001B[1;32m   1273\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# It'll attempt to gather all input into a single chunk using\u001B[39;49;00m\n\u001B[1;32m   1274\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# the `+` operator.\u001B[39;49;00m\n\u001B[1;32m   1275\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# If the input is not addable, then we'll assume that we can\u001B[39;49;00m\n\u001B[1;32m   1276\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# only operate on the last chunk,\u001B[39;49;00m\n\u001B[1;32m   1277\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# and we'll iterate until we get to the last chunk.\u001B[39;49;00m\n\u001B[1;32m   1278\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mgot_first_val\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m   1279\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfinal\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43michunk\u001B[49m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/site-packages/langchain_core/runnables/base.py:5262\u001B[0m, in \u001B[0;36mRunnableBindingBase.transform\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m   5256\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtransform\u001B[39m(\n\u001B[1;32m   5257\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   5258\u001B[0m     \u001B[38;5;28minput\u001B[39m: Iterator[Input],\n\u001B[1;32m   5259\u001B[0m     config: Optional[RunnableConfig] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   5260\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m   5261\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[Output]:\n\u001B[0;32m-> 5262\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbound\u001B[38;5;241m.\u001B[39mtransform(\n\u001B[1;32m   5263\u001B[0m         \u001B[38;5;28minput\u001B[39m,\n\u001B[1;32m   5264\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_merge_configs(config),\n\u001B[1;32m   5265\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m{\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkwargs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs},\n\u001B[1;32m   5266\u001B[0m     )\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/site-packages/langchain_core/runnables/base.py:1288\u001B[0m, in \u001B[0;36mRunnable.transform\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m   1285\u001B[0m             final \u001B[38;5;241m=\u001B[39m ichunk\n\u001B[1;32m   1287\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m got_first_val:\n\u001B[0;32m-> 1288\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstream(final, config, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:360\u001B[0m, in \u001B[0;36mBaseChatModel.stream\u001B[0;34m(self, input, config, stop, **kwargs)\u001B[0m\n\u001B[1;32m    353\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    354\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_llm_error(\n\u001B[1;32m    355\u001B[0m         e,\n\u001B[1;32m    356\u001B[0m         response\u001B[38;5;241m=\u001B[39mLLMResult(\n\u001B[1;32m    357\u001B[0m             generations\u001B[38;5;241m=\u001B[39m[[generation]] \u001B[38;5;28;01mif\u001B[39;00m generation \u001B[38;5;28;01melse\u001B[39;00m []\n\u001B[1;32m    358\u001B[0m         ),\n\u001B[1;32m    359\u001B[0m     )\n\u001B[0;32m--> 360\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m    361\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    362\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_llm_end(LLMResult(generations\u001B[38;5;241m=\u001B[39m[[generation]]))\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:340\u001B[0m, in \u001B[0;36mBaseChatModel.stream\u001B[0;34m(self, input, config, stop, **kwargs)\u001B[0m\n\u001B[1;32m    338\u001B[0m generation: Optional[ChatGenerationChunk] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    339\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 340\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_stream\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m    341\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmessage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mid\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m:\u001B[49m\n\u001B[1;32m    342\u001B[0m \u001B[43m            \u001B[49m\u001B[43mchunk\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmessage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mid\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrun-\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_id\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/site-packages/langchain_community/chat_models/ollama.py:344\u001B[0m, in \u001B[0;36mChatOllama._stream\u001B[0;34m(self, messages, stop, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m    336\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_stream\u001B[39m(\n\u001B[1;32m    337\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    338\u001B[0m     messages: List[BaseMessage],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    341\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m    342\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[ChatGenerationChunk]:\n\u001B[1;32m    343\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 344\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstream_resp\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_chat_stream\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m    345\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstream_resp\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m    346\u001B[0m \u001B[43m                \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m_chat_stream_response_to_chat_generation_chunk\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstream_resp\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/site-packages/langchain_community/chat_models/ollama.py:189\u001B[0m, in \u001B[0;36mChatOllama._create_chat_stream\u001B[0;34m(self, messages, stop, **kwargs)\u001B[0m\n\u001B[1;32m    179\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_create_chat_stream\u001B[39m(\n\u001B[1;32m    180\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    181\u001B[0m     messages: List[BaseMessage],\n\u001B[1;32m    182\u001B[0m     stop: Optional[List[\u001B[38;5;28mstr\u001B[39m]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    183\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m    184\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[\u001B[38;5;28mstr\u001B[39m]:\n\u001B[1;32m    185\u001B[0m     payload \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    186\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel,\n\u001B[1;32m    187\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_convert_messages_to_ollama_messages(messages),\n\u001B[1;32m    188\u001B[0m     }\n\u001B[0;32m--> 189\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_stream\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    190\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpayload\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpayload\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mapi_url\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbase_url\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m/api/chat\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    191\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/site-packages/langchain_community/llms/ollama.py:234\u001B[0m, in \u001B[0;36m_OllamaCommon._create_stream\u001B[0;34m(self, api_url, payload, stop, **kwargs)\u001B[0m\n\u001B[1;32m    228\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    229\u001B[0m     request_payload \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    230\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprompt\u001B[39m\u001B[38;5;124m\"\u001B[39m: payload\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprompt\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m    231\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimages\u001B[39m\u001B[38;5;124m\"\u001B[39m: payload\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimages\u001B[39m\u001B[38;5;124m\"\u001B[39m, []),\n\u001B[1;32m    232\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams,\n\u001B[1;32m    233\u001B[0m     }\n\u001B[0;32m--> 234\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43mrequests\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpost\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    235\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mapi_url\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    236\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\n\u001B[1;32m    237\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mContent-Type\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mapplication/json\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    238\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mdict\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    239\u001B[0m \u001B[43m    \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    240\u001B[0m \u001B[43m    \u001B[49m\u001B[43mjson\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_payload\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    241\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    242\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    243\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    244\u001B[0m response\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    245\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m response\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m200\u001B[39m:\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/site-packages/requests/api.py:115\u001B[0m, in \u001B[0;36mpost\u001B[0;34m(url, data, json, **kwargs)\u001B[0m\n\u001B[1;32m    103\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpost\u001B[39m(url, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, json\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    104\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Sends a POST request.\u001B[39;00m\n\u001B[1;32m    105\u001B[0m \n\u001B[1;32m    106\u001B[0m \u001B[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;124;03m    :rtype: requests.Response\u001B[39;00m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 115\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpost\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjson\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mjson\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/site-packages/requests/api.py:59\u001B[0m, in \u001B[0;36mrequest\u001B[0;34m(method, url, **kwargs)\u001B[0m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001B[39;00m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001B[39;00m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;66;03m# cases, and look like a memory leak in others.\u001B[39;00m\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m sessions\u001B[38;5;241m.\u001B[39mSession() \u001B[38;5;28;01mas\u001B[39;00m session:\n\u001B[0;32m---> 59\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/site-packages/requests/sessions.py:575\u001B[0m, in \u001B[0;36mSession.request\u001B[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[1;32m    562\u001B[0m \u001B[38;5;66;03m# Create the Request.\u001B[39;00m\n\u001B[1;32m    563\u001B[0m req \u001B[38;5;241m=\u001B[39m Request(\n\u001B[1;32m    564\u001B[0m     method\u001B[38;5;241m=\u001B[39mmethod\u001B[38;5;241m.\u001B[39mupper(),\n\u001B[1;32m    565\u001B[0m     url\u001B[38;5;241m=\u001B[39murl,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    573\u001B[0m     hooks\u001B[38;5;241m=\u001B[39mhooks,\n\u001B[1;32m    574\u001B[0m )\n\u001B[0;32m--> 575\u001B[0m prep \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprepare_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreq\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    577\u001B[0m proxies \u001B[38;5;241m=\u001B[39m proxies \u001B[38;5;129;01mor\u001B[39;00m {}\n\u001B[1;32m    579\u001B[0m settings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmerge_environment_settings(\n\u001B[1;32m    580\u001B[0m     prep\u001B[38;5;241m.\u001B[39murl, proxies, stream, verify, cert\n\u001B[1;32m    581\u001B[0m )\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/site-packages/requests/sessions.py:484\u001B[0m, in \u001B[0;36mSession.prepare_request\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m    481\u001B[0m     auth \u001B[38;5;241m=\u001B[39m get_netrc_auth(request\u001B[38;5;241m.\u001B[39murl)\n\u001B[1;32m    483\u001B[0m p \u001B[38;5;241m=\u001B[39m PreparedRequest()\n\u001B[0;32m--> 484\u001B[0m \u001B[43mp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprepare\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    485\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupper\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    486\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    487\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiles\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfiles\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    489\u001B[0m \u001B[43m    \u001B[49m\u001B[43mjson\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjson\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    490\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmerge_setting\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    491\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdict_class\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mCaseInsensitiveDict\u001B[49m\n\u001B[1;32m    492\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    493\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmerge_setting\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    494\u001B[0m \u001B[43m    \u001B[49m\u001B[43mauth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmerge_setting\u001B[49m\u001B[43m(\u001B[49m\u001B[43mauth\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mauth\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    495\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcookies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmerged_cookies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    496\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhooks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmerge_hooks\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhooks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhooks\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    497\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    498\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m p\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/site-packages/requests/models.py:370\u001B[0m, in \u001B[0;36mPreparedRequest.prepare\u001B[0;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001B[0m\n\u001B[1;32m    368\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprepare_headers(headers)\n\u001B[1;32m    369\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprepare_cookies(cookies)\n\u001B[0;32m--> 370\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprepare_body\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfiles\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjson\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    371\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprepare_auth(auth, url)\n\u001B[1;32m    373\u001B[0m \u001B[38;5;66;03m# Note that prepare_auth must be last to enable authentication schemes\u001B[39;00m\n\u001B[1;32m    374\u001B[0m \u001B[38;5;66;03m# such as OAuth to work on a fully prepared request.\u001B[39;00m\n\u001B[1;32m    375\u001B[0m \n\u001B[1;32m    376\u001B[0m \u001B[38;5;66;03m# This MUST go after prepare_auth. Authenticators could add a hook\u001B[39;00m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/site-packages/requests/models.py:510\u001B[0m, in \u001B[0;36mPreparedRequest.prepare_body\u001B[0;34m(self, data, files, json)\u001B[0m\n\u001B[1;32m    507\u001B[0m content_type \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mapplication/json\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    509\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 510\u001B[0m     body \u001B[38;5;241m=\u001B[39m \u001B[43mcomplexjson\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdumps\u001B[49m\u001B[43m(\u001B[49m\u001B[43mjson\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_nan\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    511\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m ve:\n\u001B[1;32m    512\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m InvalidJSONError(ve, request\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m)\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/json/__init__.py:238\u001B[0m, in \u001B[0;36mdumps\u001B[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001B[0m\n\u001B[1;32m    232\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    233\u001B[0m     \u001B[38;5;28mcls\u001B[39m \u001B[38;5;241m=\u001B[39m JSONEncoder\n\u001B[1;32m    234\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    235\u001B[0m \u001B[43m    \u001B[49m\u001B[43mskipkeys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskipkeys\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mensure_ascii\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_ascii\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    236\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcheck_circular\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcheck_circular\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_nan\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_nan\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    237\u001B[0m \u001B[43m    \u001B[49m\u001B[43mseparators\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mseparators\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdefault\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdefault\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msort_keys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msort_keys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m--> 238\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/json/encoder.py:200\u001B[0m, in \u001B[0;36mJSONEncoder.encode\u001B[0;34m(self, o)\u001B[0m\n\u001B[1;32m    196\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m encode_basestring(o)\n\u001B[1;32m    197\u001B[0m \u001B[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001B[39;00m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001B[39;00m\n\u001B[1;32m    199\u001B[0m \u001B[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001B[39;00m\n\u001B[0;32m--> 200\u001B[0m chunks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miterencode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mo\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_one_shot\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    201\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(chunks, (\u001B[38;5;28mlist\u001B[39m, \u001B[38;5;28mtuple\u001B[39m)):\n\u001B[1;32m    202\u001B[0m     chunks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(chunks)\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/json/encoder.py:258\u001B[0m, in \u001B[0;36mJSONEncoder.iterencode\u001B[0;34m(self, o, _one_shot)\u001B[0m\n\u001B[1;32m    253\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    254\u001B[0m     _iterencode \u001B[38;5;241m=\u001B[39m _make_iterencode(\n\u001B[1;32m    255\u001B[0m         markers, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefault, _encoder, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindent, floatstr,\n\u001B[1;32m    256\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkey_separator, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitem_separator, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msort_keys,\n\u001B[1;32m    257\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mskipkeys, _one_shot)\n\u001B[0;32m--> 258\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_iterencode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mo\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/miniconda3/envs/chatbot/lib/python3.12/json/encoder.py:180\u001B[0m, in \u001B[0;36mJSONEncoder.default\u001B[0;34m(self, o)\u001B[0m\n\u001B[1;32m    161\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdefault\u001B[39m(\u001B[38;5;28mself\u001B[39m, o):\n\u001B[1;32m    162\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001B[39;00m\n\u001B[1;32m    163\u001B[0m \u001B[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001B[39;00m\n\u001B[1;32m    164\u001B[0m \u001B[38;5;124;03m    (to raise a ``TypeError``).\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    178\u001B[0m \n\u001B[1;32m    179\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 180\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mObject of type \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mo\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    181\u001B[0m                     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mis not JSON serializable\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mTypeError\u001B[0m: Object of type StructuredTool is not JSON serializable"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3f6dd29c176520ee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1. Install dependencies",
   "id": "42e06057eee03407"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T08:10:32.249789Z",
     "start_time": "2024-08-31T08:10:28.470923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install --upgrade langchain-ollama\n",
    "%pip install --upgrade langgraph"
   ],
   "id": "d7935caedf5f6eeb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (24.0)\r\n",
      "Collecting pip\r\n",
      "  Downloading pip-24.2-py3-none-any.whl.metadata (3.6 kB)\r\n",
      "Downloading pip-24.2-py3-none-any.whl (1.8 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.8/1.8 MB\u001B[0m \u001B[31m29.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: pip\r\n",
      "  Attempting uninstall: pip\r\n",
      "    Found existing installation: pip 24.0\r\n",
      "    Uninstalling pip-24.0:\r\n",
      "      Successfully uninstalled pip-24.0\r\n",
      "Successfully installed pip-24.2\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain-ollama in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (0.1.1)\r\n",
      "Collecting langchain-ollama\r\n",
      "  Downloading langchain_ollama-0.1.3-py3-none-any.whl.metadata (1.8 kB)\r\n",
      "Collecting langchain-core<0.3.0,>=0.2.36 (from langchain-ollama)\r\n",
      "  Downloading langchain_core-0.2.37-py3-none-any.whl.metadata (6.2 kB)\r\n",
      "Requirement already satisfied: ollama<1,>=0.3.0 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from langchain-ollama) (0.3.1)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.36->langchain-ollama) (6.0.1)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.36->langchain-ollama) (1.33)\r\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.36->langchain-ollama) (0.1.77)\r\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.36->langchain-ollama) (23.2)\r\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.36->langchain-ollama) (2.7.4)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.36->langchain-ollama) (8.3.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.36->langchain-ollama) (4.9.0)\r\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from ollama<1,>=0.3.0->langchain-ollama) (0.27.0)\r\n",
      "Requirement already satisfied: anyio in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (4.4.0)\r\n",
      "Requirement already satisfied: certifi in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (2024.6.2)\r\n",
      "Requirement already satisfied: httpcore==1.* in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (1.0.5)\r\n",
      "Requirement already satisfied: idna in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (3.7)\r\n",
      "Requirement already satisfied: sniffio in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (1.3.1)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (0.14.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.36->langchain-ollama) (3.0.0)\r\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.36->langchain-ollama) (3.10.4)\r\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.36->langchain-ollama) (2.32.3)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.36->langchain-ollama) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.36->langchain-ollama) (2.18.4)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.36->langchain-ollama) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.36->langchain-ollama) (2.2.1)\r\n",
      "Downloading langchain_ollama-0.1.3-py3-none-any.whl (14 kB)\r\n",
      "Downloading langchain_core-0.2.37-py3-none-any.whl (396 kB)\r\n",
      "Installing collected packages: langchain-core, langchain-ollama\r\n",
      "  Attempting uninstall: langchain-core\r\n",
      "    Found existing installation: langchain-core 0.2.22\r\n",
      "    Uninstalling langchain-core-0.2.22:\r\n",
      "      Successfully uninstalled langchain-core-0.2.22\r\n",
      "  Attempting uninstall: langchain-ollama\r\n",
      "    Found existing installation: langchain-ollama 0.1.1\r\n",
      "    Uninstalling langchain-ollama-0.1.1:\r\n",
      "      Successfully uninstalled langchain-ollama-0.1.1\r\n",
      "Successfully installed langchain-core-0.2.37 langchain-ollama-0.1.3\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting langgraph\r\n",
      "  Downloading langgraph-0.2.15-py3-none-any.whl.metadata (13 kB)\r\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.2.27 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from langgraph) (0.2.37)\r\n",
      "Collecting langgraph-checkpoint<2.0.0,>=1.0.2 (from langgraph)\r\n",
      "  Downloading langgraph_checkpoint-1.0.8-py3-none-any.whl.metadata (4.5 kB)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2.27->langgraph) (6.0.1)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2.27->langgraph) (1.33)\r\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2.27->langgraph) (0.1.77)\r\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2.27->langgraph) (23.2)\r\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2.27->langgraph) (2.7.4)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2.27->langgraph) (8.3.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2.27->langgraph) (4.9.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.27->langgraph) (3.0.0)\r\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph) (3.10.4)\r\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph) (2.32.3)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.27->langgraph) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.27->langgraph) (2.18.4)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph) (2.2.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/chatbot/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph) (2024.6.2)\r\n",
      "Downloading langgraph-0.2.15-py3-none-any.whl (90 kB)\r\n",
      "Downloading langgraph_checkpoint-1.0.8-py3-none-any.whl (15 kB)\r\n",
      "Installing collected packages: langgraph-checkpoint, langgraph\r\n",
      "Successfully installed langgraph-0.2.15 langgraph-checkpoint-1.0.8\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2. Initialize the model",
   "id": "5bf296f5649e9466"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T08:12:14.130409Z",
     "start_time": "2024-08-31T08:12:13.668265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.checkpoint.memory import MemorySaver"
   ],
   "id": "a1ee1775c6fa5780",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:31:22.466664Z",
     "start_time": "2024-08-31T14:31:22.426028Z"
    }
   },
   "cell_type": "code",
   "source": "model = ChatOllama(model=\"llama3-groq-tool-use\", temperature=0)",
   "id": "8c18b952c8ac793c",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T18:23:28.515925Z",
     "start_time": "2024-08-31T18:23:28.512402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create the primary assistant prompt template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "primary_assistant_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant tasked with answering user questions. \"\n",
    "            \"You have access to two tools: retrieve_documents and web_search. \"\n",
    "            \"For any user questions about LLM agents, use the retrieve_documents tool to get information for a vectorstore. \"\n",
    "            \"For any other questions, such as questions about current events, use the web_search tool to get information from the web. \",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = primary_assistant_prompt | primary_assistant_prompt"
   ],
   "id": "fbe7f545cbb7af8f",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3. Initialize the tools",
   "id": "602e2de1f65ba9f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:31:24.006222Z",
     "start_time": "2024-08-31T14:31:24.003317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "@tool\n",
    "def search(query: str):\n",
    "    \"\"\"Run web search on the question.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The query to search for.\n",
    "\n",
    "    Returns:\n",
    "        str: The answer to the question.\n",
    "    \"\"\"\n",
    "    if \"sf\" in query.lower() or \"san francisco\" in query.lower():\n",
    "        return \"It's 60 degrees and foggy.\"\n",
    "    return \"It's 90 degrees and sunny.\"\n",
    "\n",
    "\n",
    "tools = [search]\n",
    "\n",
    "tool_node = ToolNode(tools)"
   ],
   "id": "fbe596a9182ac27d",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4. Initialize graph with state",
   "id": "19dbda70f1ead831"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:31:24.606727Z",
     "start_time": "2024-08-31T14:31:24.604132Z"
    }
   },
   "cell_type": "code",
   "source": "from langgraph.graph import END, START, StateGraph, MessagesState",
   "id": "1f6eaead599cb0a9",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:31:24.849481Z",
     "start_time": "2024-08-31T14:31:24.846771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Annotated, Literal, TypedDict\n",
    "\n",
    "# Define the function that determines whether to continue or not\n",
    "def should_continue(state: MessagesState) -> Literal[\"tools\", END]:\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    # If the LLM makes a tool call, then we route to the \"tools\" node\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    # Otherwise, we stop (reply to the user)\n",
    "    return END\n",
    "\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state: MessagesState):\n",
    "    messages = state['messages']\n",
    "    response = model.invoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}"
   ],
   "id": "e01eed6b12247743",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 5. Define graph nodes",
   "id": "5073f8d2881657c0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5.1 CREATE AN ASSISTANT CLASS",
   "id": "71662e23dc512dcc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T18:28:49.874971Z",
     "start_time": "2024-08-31T18:28:49.859367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.runnables import Runnable, RunnableConfig\n",
    "class Assistant:\n",
    "    def __init__(self, runnable: Runnable):\n",
    "        \"\"\"\n",
    "        Initialize the Assistant with a runnable object.\n",
    "\n",
    "        Args:\n",
    "            runnable (Runnable): The runnable instance to invoke.\n",
    "        \"\"\"\n",
    "        self.runnable = runnable\n",
    "\n",
    "    def __call__(self, state: State, config: RunnableConfig):\n",
    "        \"\"\"\n",
    "        Call method to invoke the LLM and handle its responses.\n",
    "        Re-prompt the assistant if the response is not a tool call or meaningful text.\n",
    "\n",
    "        Args:\n",
    "            state (State): The current state containing messages.\n",
    "            config (RunnableConfig): The configuration for the runnable.\n",
    "\n",
    "        Returns:\n",
    "            dict: The final state containing the updated messages.\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            result = self.runnable.invoke(state)  # Invoke the LLM\n",
    "            if not result.tool_calls and (\n",
    "                not result.content\n",
    "                or isinstance(result.content, list)\n",
    "                and not result.content[0].get(\"text\")\n",
    "            ):\n",
    "                messages = state[\"messages\"] + [(\"user\", \"Respond with a real output.\")]\n",
    "                state = {**state, \"messages\": messages}\n",
    "            else:\n",
    "                break\n",
    "        return {\"messages\": result}\n",
    "\n",
    "\n",
    "# Create the primary assistant prompt template\n",
    "primary_assistant_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant tasked with answering user questions. \"\n",
    "            \"You have access to two tools: retrieve_documents and web_search. \"\n",
    "            \"For any user questions about LLM agents, use the retrieve_documents tool to get information for a vectorstore. \"\n",
    "            \"For any other questions, such as questions about current events, use the web_search tool to get information from the web. \",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Prompt our LLM and bind tools\n",
    "assistant_runnable = primary_assistant_prompt | llm.bind_tools(tools)"
   ],
   "id": "2b4630b27f91b1d2",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'State' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[55], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain_core\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrunnables\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Runnable, RunnableConfig\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;43;01mclass\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;21;43;01mAssistant\u001B[39;49;00m\u001B[43m:\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mdef\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrunnable\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mRunnable\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;250;43m        \u001B[39;49m\u001B[38;5;124;43;03m\"\"\"\u001B[39;49;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;124;43;03m        Initialize the Assistant with a runnable object.\u001B[39;49;00m\n\u001B[1;32m      6\u001B[0m \n\u001B[1;32m      7\u001B[0m \u001B[38;5;124;43;03m        Args:\u001B[39;49;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;124;43;03m            runnable (Runnable): The runnable instance to invoke.\u001B[39;49;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;124;43;03m        \"\"\"\u001B[39;49;00m\n",
      "Cell \u001B[0;32mIn[55], line 12\u001B[0m, in \u001B[0;36mAssistant\u001B[0;34m()\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;124;03m    Initialize the Assistant with a runnable object.\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \n\u001B[1;32m      7\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;124;03m        runnable (Runnable): The runnable instance to invoke.\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrunnable \u001B[38;5;241m=\u001B[39m runnable\n\u001B[0;32m---> 12\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, state: \u001B[43mState\u001B[49m, config: RunnableConfig):\n\u001B[1;32m     13\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;124;03m    Call method to invoke the LLM and handle its responses.\u001B[39;00m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;124;03m    Re-prompt the assistant if the response is not a tool call or meaningful text.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;124;03m        dict: The final state containing the updated messages.\u001B[39;00m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m     24\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n",
      "\u001B[0;31mNameError\u001B[0m: name 'State' is not defined"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5.2 Create the graph",
   "id": "b6a6fa4e139f8232"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:31:25.472607Z",
     "start_time": "2024-08-31T14:31:25.470799Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define a new graph\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)"
   ],
   "id": "aaf48e4043c219b3",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:31:26.086507Z",
     "start_time": "2024-08-31T14:31:26.084238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set the entrypoint as `agent`\n",
    "# This means that this node is the first one called\n",
    "workflow.add_edge(START, \"agent\")"
   ],
   "id": "9ffac182e7bb4678",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:31:26.557533Z",
     "start_time": "2024-08-31T14:31:26.555748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "workflow.add_conditional_edges(\n",
    "    # First, we define the start node. We use `agent`.\n",
    "    # This means these are the edges taken after the `agent` node is called.\n",
    "    \"agent\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_continue,\n",
    ")"
   ],
   "id": "7b093625cfb9e396",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:31:27.037063Z",
     "start_time": "2024-08-31T14:31:27.035137Z"
    }
   },
   "cell_type": "code",
   "source": "workflow.add_edge(\"tools\", 'agent')",
   "id": "f1c8cb060ca934b",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:31:27.513164Z",
     "start_time": "2024-08-31T14:31:27.511639Z"
    }
   },
   "cell_type": "code",
   "source": "checkpointer = MemorySaver()",
   "id": "4ca945810b29ce26",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "630fc62f609f1a98"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 6. Define entry point and graph edges ",
   "id": "35283fd2a5eabd1e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 7. Compile the graph",
   "id": "d79a75a41314b19f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:31:29.501285Z",
     "start_time": "2024-08-31T14:31:29.497924Z"
    }
   },
   "cell_type": "code",
   "source": "app = workflow.compile(checkpointer=checkpointer)",
   "id": "5f7f31cf12f49900",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:31:31.879452Z",
     "start_time": "2024-08-31T14:31:30.044375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_state = app.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What is the weather in San Francisco ? Use the tools at your disposal at the best of your ability.\")]},\n",
    "    config={\"configurable\": {\"thread_id\": 42}}\n",
    ")\n",
    "final_state[\"messages\"][-1].content# 8. Run Graph\n"
   ],
   "id": "3de0595630b986f3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I can provide you with the current weather conditions and forecast for San Francisco. Would you like me to fetch that information?'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a8010d636753bf60"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
