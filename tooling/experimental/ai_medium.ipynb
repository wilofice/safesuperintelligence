{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-10T10:57:03.935167Z",
     "start_time": "2025-01-10T10:57:03.930530Z"
    }
   },
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from typing import Literal"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T10:57:03.940360Z",
     "start_time": "2025-01-10T10:57:03.937206Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ],
   "id": "24bc41e827097890",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T10:57:03.948614Z",
     "start_time": "2025-01-10T10:57:03.941505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "@tool\n",
    "def search(query: str):\n",
    "    \"\"\"Run web search on the question.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The query to search for.\n",
    "\n",
    "    Returns:\n",
    "        str: The answer to the question.\n",
    "    \"\"\"\n",
    "    if \"sf\" in query.lower() or \"san francisco\" in query.lower():\n",
    "        return \"It's 60 degrees and foggy.\"\n",
    "    return \"It's 90 degrees and sunny.\"\n",
    "\n",
    "\n",
    "tools = [search]"
   ],
   "id": "4e6aaacd5db2287a",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T10:57:03.987976Z",
     "start_time": "2025-01-10T10:57:03.949740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm = ChatOllama(model=\"llama3-groq-tool-use\", temperature=0)\n",
    "#model = ChatOllama(model=\"llama3.1\", temperature=0)\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# The first argument is the unique node name\n",
    "# The second argument is the function or object that will be called whenever\n",
    "# the node is used.\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ],
   "id": "2ff47226e83667c4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1081abb90>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T10:57:03.991854Z",
     "start_time": "2025-01-10T10:57:03.989260Z"
    }
   },
   "cell_type": "code",
   "source": "tool_node = ToolNode(tools=tools)",
   "id": "cff1366feb79a606",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T10:57:03.995969Z",
     "start_time": "2025-01-10T10:57:03.993233Z"
    }
   },
   "cell_type": "code",
   "source": "graph_builder.add_node(\"tools\", tool_node)",
   "id": "d5498cc944a80b0a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1081abb90>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T10:57:04.003603Z",
     "start_time": "2025-01-10T10:57:03.998134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def route_tools(\n",
    "    state: State,\n",
    "):\n",
    "    \"\"\"\n",
    "    Use in the conditional_edge to route to the ToolNode if the last message\n",
    "    has tool calls. Otherwise, route to the end.\n",
    "    \"\"\"\n",
    "    if isinstance(state, list):\n",
    "        ai_message = state[-1]\n",
    "    elif messages := state.get(\"messages\", []):\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "\n",
    "# The `tools_condition` function returns \"tools\" if the chatbot asks to use a tool, and \"END\" if\n",
    "# it is fine directly responding. This conditional routing defines the main agent loop.\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    route_tools,\n",
    "    # The following dictionary lets you tell the graph to interpret the condition's outputs as a specific node\n",
    "    # It defaults to the identity function, but if you\n",
    "    # want to use a node named something else apart from \"tools\",\n",
    "    # You can update the value of the dictionary to something else\n",
    "    # e.g., \"tools\": \"my_tools\"\n",
    "    {\"tools\": \"tools\", END: END},\n",
    ")\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph = graph_builder.compile()"
   ],
   "id": "bb984cd8cd86e9bf",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T10:57:04.006532Z",
     "start_time": "2025-01-10T10:57:04.004420Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def stream_graph_updates(user_input: str):\n",
    "    for event in graph.stream({\"messages\": [(\"user\", user_input)]}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "                  "
   ],
   "id": "77ea6f8996148e6f",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T10:58:15.927706Z",
     "start_time": "2025-01-10T10:58:15.389394Z"
    }
   },
   "cell_type": "code",
   "source": "stream_graph_updates(\"User: Ask me a question about a subject of your choice. The answer must be yes or no.\")",
   "id": "be2f88b6c97f38e4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Is Pluto considered a planet?\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T10:58:08.491757Z",
     "start_time": "2025-01-10T10:58:06.250767Z"
    }
   },
   "cell_type": "code",
   "source": "stream_graph_updates(\"User: Using the search function, get the temperature in San Francisco\")",
   "id": "36cefeeab1e1627a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: \n",
      "Assistant: It's 60 degrees and foggy.\n",
      "Assistant: The current temperature in San Francisco is 60 degrees, and it's quite foggy.\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break"
   ],
   "id": "9cbeb7abe3e21a17",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T04:17:58.897006Z",
     "start_time": "2025-01-17T04:17:58.881079Z"
    }
   },
   "cell_type": "code",
   "source": "from scraping.lib import testimport",
   "id": "17568d75a892354f",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'errors'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[53], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscraping\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m testimport\n",
      "File \u001B[0;32m~/Desktop/d/safesuperintelligence/scraping/lib.py:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merrors\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ImproperlyConfigured\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21muser_to_names\u001B[39m(user: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mtuple\u001B[39m[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mstr\u001B[39m]:\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m user \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'errors'"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T04:18:26.285567Z",
     "start_time": "2025-01-17T04:18:26.273942Z"
    }
   },
   "cell_type": "code",
   "source": "testimport()",
   "id": "afee3c55a13b6600",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testimport' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[54], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtestimport\u001B[49m()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'testimport' is not defined"
     ]
    }
   ],
   "execution_count": 54
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
