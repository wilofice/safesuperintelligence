{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f9797059d05c1ec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 0. Experimental "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f756cc92dd69fd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68b2dcc64ab9aa0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T05:44:33.402129Z",
     "start_time": "2024-09-10T05:44:30.124808Z"
    }
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade langchain_experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebf97f61b46ef9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T09:44:51.819335Z",
     "start_time": "2024-07-21T09:44:51.816680Z"
    }
   },
   "outputs": [],
   "source": [
    "model = model.bind_tools(\n",
    "    tools=[\n",
    "        {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, \" \"e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"unit\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    "    function_call={\"name\": \"get_current_weather\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241a36bba72c168c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T09:44:52.313885Z",
     "start_time": "2024-07-21T09:44:51.819942Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model.invoke(\"what is the weather in Boston?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84e5972a0d7da1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T09:44:52.315386Z",
     "start_time": "2024-07-21T09:44:52.315344Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from typing import Annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aadf010de15697a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scraping.db.documents import ArticleDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c38f3664409351",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_medium_article(link: Annotated[str, \"The link of the Medium article\"],) -> str:\n",
    "    \"\"\"Get a medium article from the given link\"\"\"\n",
    "    filter_options = {\"link\": link}\n",
    "    article = ArticleDocument.get(**filter_options)\n",
    "    return article.content['Content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618c8cbdc9ff09b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "link = \"https://medium.com/ai-in-plain-english/claude-3-5-sonnet-why-it-is-better-than-chatgpt-7709d7cbc237\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bebaf802506849b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "r = get_medium_article(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9198f7f25f825dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50539742f09c9f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_medium_article.args_schema.schema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T10:07:25.614491Z",
     "start_time": "2024-07-21T10:07:25.611422Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "\n",
    "class AnswerWithJustification(BaseModel):\n",
    "    \"\"\"An answer to the user question along with justification for the answer.\"\"\"\n",
    "    answer: str\n",
    "    justification: str\n",
    "    \n",
    "model = OllamaFunctions(model=\"llama3-groq-tool-use\")\n",
    "structured_llm = model.with_structured_output(AnswerWithJustification, include_raw=True)\n",
    "#model = OllamaFunctions(model=\"llama3-groq-tool-use\", format=\"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b317943f6c0c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Use the tools at your disposal at the best of your ability.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b088d08b54d9195d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T09:44:54.797220Z",
     "start_time": "2024-07-21T09:44:54.794464Z"
    }
   },
   "outputs": [],
   "source": [
    "tools = [get_medium_article]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab977ace2734939",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9123abb197e53763",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775ba6c956606299",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T09:46:19.294179Z",
     "start_time": "2024-07-21T09:46:19.291791Z"
    }
   },
   "outputs": [],
   "source": [
    "input = \"Can you tell me what this Medium article is about ? Here is the link to the article: https://medium.com/ai-in-plain-english/claude-3-5-sonnet-why-it-is-better-than-chatgpt-7709d7cbc237\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea4107139a6a462",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_msg = chain.invoke(\n",
    "    {\n",
    "        \"input\": input,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d439cfe782a8118c",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_tools = {\"get_medium_article\" : get_medium_article}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc5b569a8b82e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [ai_msg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee7e948b6b0fa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = available_tools[tool_call[\"name\"].lower()]\n",
    "    if selected_tool:\n",
    "        tool_msg = selected_tool.invoke(tool_call)\n",
    "        messages.append(tool_msg)\n",
    "    else:\n",
    "        raise ValueError(f\"No tool called {tool_call['name'].lower()} was found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32890d5b719cc5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68542a7df1d402",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14596746a959505",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T09:47:59.568444Z",
     "start_time": "2024-07-21T09:47:59.564989Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Make sure to use the get_medium_article tool to retrieve the content of the Medium article provided to you.\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3794715e3bf2705",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T10:10:44.564972Z",
     "start_time": "2024-07-21T10:10:44.563136Z"
    }
   },
   "outputs": [],
   "source": [
    "agent = create_tool_calling_agent(model, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23b527f2e28be01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T10:10:51.612918Z",
     "start_time": "2024-07-21T10:10:51.610474Z"
    }
   },
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c9fbfa3966379d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T10:10:55.471904Z",
     "start_time": "2024-07-21T10:10:55.373262Z"
    }
   },
   "outputs": [],
   "source": [
    "result = agent_executor.invoke({\"input\": input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6dd29c176520ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42e06057eee03407",
   "metadata": {},
   "source": [
    "# 1. Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7935caedf5f6eeb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T08:10:32.249789Z",
     "start_time": "2024-08-31T08:10:28.470923Z"
    }
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install --upgrade langchain-ollama\n",
    "%pip install --upgrade langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf296f5649e9466",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# 2. Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ee1775c6fa5780",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T08:12:14.130409Z",
     "start_time": "2024-08-31T08:12:13.668265Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.checkpoint.memory import MemorySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c18b952c8ac793c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:31:22.466664Z",
     "start_time": "2024-08-31T14:31:22.426028Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = ChatOllama(model=\"llama3-groq-tool-use\", temperature=1)\n",
    "#model = ChatOllama(model=\"llama3.1\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe7f545cbb7af8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T18:23:28.515925Z",
     "start_time": "2024-08-31T18:23:28.512402Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the primary assistant prompt template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "primary_assistant_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant tasked with answering user questions. \"\n",
    "            \"You have access to two tools: retrieve_documents and web_search. \"\n",
    "            \"For any user questions about LLM agents, use the retrieve_documents tool to get information for a vectorstore. \"\n",
    "            \"For any other questions, such as questions about current events, use the web_search tool to get information from the web. \",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f8edf86d805fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "602e2de1f65ba9f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# 3. Initialize the tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe596a9182ac27d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:31:24.006222Z",
     "start_time": "2024-08-31T14:31:24.003317Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "@tool\n",
    "def search(query: str):\n",
    "    \"\"\"Run web search on the question.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The query to search for.\n",
    "\n",
    "    Returns:\n",
    "        str: The answer to the question.\n",
    "    \"\"\"\n",
    "    if \"sf\" in query.lower() or \"san francisco\" in query.lower():\n",
    "        return \"It's 60 degrees and foggy.\"\n",
    "    return \"It's 90 degrees and sunny.\"\n",
    "\n",
    "\n",
    "tools = [search]\n",
    "\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dbda70f1ead831",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# 4. Initialize graph with state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6eaead599cb0a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:31:24.606727Z",
     "start_time": "2024-08-31T14:31:24.604132Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import END, START, StateGraph, MessagesState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01eed6b12247743",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:31:24.849481Z",
     "start_time": "2024-08-31T14:31:24.846771Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal, TypedDict\n",
    "\n",
    "# Define the function that determines whether to continue or not\n",
    "def should_continue(state: MessagesState) -> Literal[\"tools\", END]:\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    # If the LLM makes a tool call, then we route to the \"tools\" node\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    # Otherwise, we stop (reply to the user)\n",
    "    return END\n",
    "\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state: MessagesState):\n",
    "    messages = state['messages']\n",
    "    response = model.invoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5073f8d2881657c0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# 5. Define graph nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71662e23dc512dcc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 5.1 CREATE AN ASSISTANT CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4630b27f91b1d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T18:28:49.874971Z",
     "start_time": "2024-08-31T18:28:49.859367Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import Runnable, RunnableConfig\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.runnables import Runnable, RunnableConfig\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "from typing import Annotated, List\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "\n",
    "\n",
    "class Assistant:\n",
    "    def __init__(self, runnable: Runnable):\n",
    "        \"\"\"\n",
    "        Initialize the Assistant with a runnable object.\n",
    "\n",
    "        Args:\n",
    "            runnable (Runnable): The runnable instance to invoke.\n",
    "        \"\"\"\n",
    "        self.runnable = runnable\n",
    "\n",
    "    def __call__(self, state: State, config: RunnableConfig):\n",
    "        \"\"\"\n",
    "        Call method to invoke the LLM and handle its responses.\n",
    "        Re-prompt the assistant if the response is not a tool call or meaningful text.\n",
    "\n",
    "        Args:\n",
    "            state (State): The current state containing messages.\n",
    "            config (RunnableConfig): The configuration for the runnable.\n",
    "\n",
    "        Returns:\n",
    "            dict: The final state containing the updated messages.\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            result = self.runnable.invoke(state)  # Invoke the LLM\n",
    "            if not result.tool_calls and (\n",
    "                not result.content\n",
    "                or isinstance(result.content, list)\n",
    "                and not result.content[0].get(\"text\")\n",
    "            ):\n",
    "                messages = state[\"messages\"] + [(\"user\", \"Respond with a real output.\")]\n",
    "                state = {**state, \"messages\": messages}\n",
    "            else:\n",
    "                break\n",
    "        return {\"messages\": result}\n",
    "\n",
    "\n",
    "# Create the primary assistant prompt template\n",
    "primary_assistant_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant tasked with answering user questions. \"\n",
    "            \"You have access to one tool: search .\"\n",
    "            \"For any questions, such as questions about current events, use the search tool to get real time information from the web. \",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Prompt our LLM and bind tools\n",
    "assistant_runnable = primary_assistant_prompt | model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a6fa4e139f8232",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 5.2 Create the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf48e4043c219b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:31:25.472607Z",
     "start_time": "2024-08-31T14:31:25.470799Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a new graph\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", Assistant(assistant_runnable))\n",
    "workflow.add_node(\"tools\", tool_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffac182e7bb4678",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:31:26.086507Z",
     "start_time": "2024-08-31T14:31:26.084238Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the entrypoint as `agent`\n",
    "# This means that this node is the first one called\n",
    "workflow.add_edge(START, \"agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b093625cfb9e396",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:31:26.557533Z",
     "start_time": "2024-08-31T14:31:26.555748Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "workflow.add_conditional_edges(\n",
    "    # First, we define the start node. We use `agent`.\n",
    "    # This means these are the edges taken after the `agent` node is called.\n",
    "    \"agent\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_continue,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c8cb060ca934b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:31:27.037063Z",
     "start_time": "2024-08-31T14:31:27.035137Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "workflow.add_edge(\"tools\", 'agent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca945810b29ce26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:31:27.513164Z",
     "start_time": "2024-08-31T14:31:27.511639Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpointer = MemorySaver()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630fc62f609f1a98",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35283fd2a5eabd1e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# 6. Define entry point and graph edges "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79a75a41314b19f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# 7. Compile the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7f31cf12f49900",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:31:29.501285Z",
     "start_time": "2024-08-31T14:31:29.497924Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "app = workflow.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b3f4a8-93b4-4d1e-8886-5858dd674db8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de0595630b986f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T14:31:31.879452Z",
     "start_time": "2024-08-31T14:31:30.044375Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_state = app.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What is the weather in San Francisco ? Use the search function to find the latest information.\")]},\n",
    "    config={\"configurable\": {\"thread_id\": 1}}\n",
    ")\n",
    "final_state[\"messages\"][-1].content# 8. Run Graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1095b58-3de4-4f04-bcbd-c224241be87d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_state = app.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What is the weather in Paris ? Use the search function to find the latest information.\")]},\n",
    "    config={\"configurable\": {\"thread_id\": 1}}\n",
    ")\n",
    "final_state[\"messages\"][-1].content# 8. Run Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18433265-e441-4a7a-8df8-7631be699b31",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
